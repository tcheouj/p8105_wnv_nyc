---
title: "eda_jt3466"
author: "Johnstone Tcheou"
date: "2024-11-25"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(httr)
library(GSODR)
library(sf)
library(patchwork)
```


```{r wnv data import, echo = FALSE}
zip_nbhd <- read_html("https://p8105.com/data/zip_codes.html") |>
  html_table() |>
  first() |>
  janitor::clean_names() |>
  filter(!(county == "New York" & zip_code %in% c(10463, 11201))) |>#duplicated zip codes, both are *not* in New York County
  mutate(borough = str_replace_all(county, c(
    "Kings" = "Brooklyn",
    "New York" = "Manhattan",
    "Richmond" = "Staten Island"
  ))) |>
  select(zip_code, borough, neighborhood)


## 2021 - 2023 are simple HTML tables
mosquitoes_2024_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2024.page"
mosquitoes_2023_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2023.page"
mosquitoes_2022_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2022.page"
mosquitoes_2021_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2021.page"

### 2024
mosquitoes_2024_table <- read_csv("data/mosquitoes_2024.csv") |>
  pivot_longer(cols = starts_with("date"), values_to = "date") |>
  select(-name, -detection_type) |> 
  mutate(
    date = case_match(
      date,
      "8/5/5024" ~ "8/5/2024",
      .default = date # one observation, 11426, with year miswritten as 5024-08-05 instead of 2024-08-05
    ),
    date = lubridate::mdy(date)
  ) |> 
  na.omit() 
   
### 2023
mosquitoes_2023_table <- mosquitoes_2023_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-neighborhood, -download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2023),
    date = lubridate::mdy(date)
  )

### 2022
mosquitoes_2022_table <- mosquitoes_2022_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2022),
    date = lubridate::mdy(date)
  )

### 2021
mosquitoes_2021_table <- mosquitoes_2021_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2021),
    date = lubridate::mdy(date)
  ) |> 
  mutate(
    zip_code = case_when(
      zip_code == 1123 ~ 11236, # data entry error on the website, where 1123 is missing the last digit - per https://www.nyc.gov/assets/doh/downloads/pdf/wnv/2021/wnv-activity-bk-08192021.pdf it should be 11236
    .default = zip_code
    )
  )

wnv_mosquito_detection <- bind_rows(
  mosquitoes_2024_table,
  mosquitoes_2023_table,
  mosquitoes_2022_table,
  mosquitoes_2021_table,
) |> 
  left_join(y = zip_nbhd, by = join_by(zip_code)) |>
  select(zip_code, borough.x, date, neighborhood) |> 
  rename(borough = borough.x) |> # one ZIP code, 10000 has NA for borough as it is not in ZIP list - Central Park based on a Google search
  mutate(
    borough = case_when(
      zip_code == 10000 ~ "Manhattan",
      .default = borough
    ),
    neighborhood = case_when(
      zip_code == 10000 ~ "Central Park",
      .default = neighborhood
    )
  )

######### Heat Vulnerability by Neighborhood
heat_vuln <- read_csv("data/heat_vulnerability.csv") |>
  janitor::clean_names() #Already clean! Thank you NYC environment and health

######### West Nile Virus Cases by Year and Borough
wnv_cases <- read_csv("data/wnv_cases.csv") |>
  janitor::clean_names() |>
  pivot_longer(cols = c(
    bronx,
    brooklyn,
    manhattan,
    queens,
    staten_island
  ),
  names_to = "borough",
  values_to = "wnv_cases")

# May need to use ZCTA level HVI data instead of NTA level HVI 
# - ZCTA is designed to approximate ZIP codes, when our WNV counts are by ZIP code

hvi_zcta <- read_csv("https://data.cityofnewyork.us/resource/4mhf-duep.csv")  |> 
  rename(zip_code = zcta20)

inner_join(wnv_mosquito_detection, hvi_zcta, by = join_by(zip_code)) |> 
  group_by(hvi) |> 
  summarize(
    count = n()
  )
```

```{r add no wnv zctas}
# get ZIP codes that did not have counts of WNV using anti_join with original ZIP code list (for generating proportions and to ensure ZIPs without cases can still be mapped later)


all_zctas <-
  zip_nbhd |> 
  pull(zip_code) |> 
  c(10000) |> 
  expand_grid(
    zip_code = _,
    year = c(2021, 2022, 2023, 2024),
    count = 0
  )

fill_neg_zctas <- function(yr) {
  
  pos = 
    wnv_mosquito_detection |> 
    mutate(
      year = year(date)
    ) |> 
    filter(year == yr) |> 
    group_by(zip_code, neighborhood, year) |> 
    summarize(
      count = n()
    ) |>
    arrange(count)
  
  neg = 
    all_zctas |> 
    filter(year == yr) |> 
    anti_join(pos, by = join_by(zip_code))
  
  rbind(pos, neg)
    
}

wnv_mosquito_data <-
  tibble(
    years = c(2021, 2022, 2023, 2024),
    mosquito_data = map(years, fill_neg_zctas)
  ) |> 
  unnest(mosquito_data) |> 
  select(-years) |> 
  left_join(zip_nbhd, by = join_by(zip_code, neighborhood)) |> # rejoin borough variable from original ZIP code list 
  mutate(
    borough = case_when(
      zip_code == 10000 ~ "Manhattan",
      .default = borough
    ),
    neighborhood = case_when(
      zip_code == 10000 ~ "Central Park",
      .default = neighborhood
    )
  )

wnv_mosquito_data |> 
  pull(count) |> 
  sum() # 2924

wnv_mosquito_detection |> 
  nrow() # 2924 - matches

```


```{r gsodr data import, echo = FALSE}

# Bushwick is the geographical center of NYC, providing the following latitude and longitude coordinates 
# Wakefield at the top of the Bronx is around 33 km/20.5 mi away from Bushwick, creating the radius of stations to search for
# Filter for non NYC stations, by filtering out NJ and filtering out Kings Point and Sandy Hook and other Long Island locations

station_ids <-
  nearest_stations(
    LAT = 40.6958, 
    LON = -73.9171,
    distance = 20
  ) |> 
  filter(STATE != "NJ" & !(NAME %in% c("KINGS POINT", 
                                       "SANDY HOOK", 
                                       "BERGEN POINT", 
                                       "MITCHEL FIELD", 
                                       "HEMPSTEAD MITCHELL FLD AFB", 
                                       "AMBROSE LIGHT  NY", 
                                       "AMBROSE / FT. TILDEN", 
                                       "FREEPORT"))) |> 
  filter(!(STNID %in% c("999999-14732",
                        "725033-94728",
                        "725060-94728",
                        "999999-94728",
                        "744976-99999",
                        "999999-14786",
                        "999999-94789",
                        "725026-99999",
                        "997439-99999"))) |> # Some stations only have historical data preceding our years of interest of 2021-2024, these have been filtered out
  janitor::clean_names() |> 
  pull(stnid)

weather_2021_2024 <-
  get_GSOD(
    years = c(2021:2024),
    station = station_ids
  ) |> 
  janitor::clean_names() |>
  select(name, latitude, longitude, yearmoda, temp, max, min, prcp, dewp) |>  # retain relevant variables - station name, latitude and longitude, date (yearmoda) mean temperature (temp), mean precipitation (prcp), mean dew point (dewp) to get an idea of water content in the air, max temperature, and min temperature
  mutate(
    temp = (temp * 9/5) + 32, # convert from Celsius to Fahrenheit
    max = (max * 9/5) + 32,
    min = (min * 9/5) + 32,
    prcp = (prcp * 0.0393701), # convert from mm to in
    year = year(yearmoda), # give stations more intuitive names
    name = case_match(
      name, 
      "PORT AUTH DOWNTN MANHATTAN WALL ST HEL" ~ "Wall St",
      "LA GUARDIA AIRPORT" ~ "LGA",
      "CENTRAL PARK" ~ "Central Park",
      "JOHN F KENNEDY INTERNATIONAL AIRPORT" ~ "JFK",
      "THE BATTERY" ~ "The Battery"
    )
  )

# is there much variation between the different weather stations?

weather_2021_2024 |>
#  filter(name %in% c("Central Park", "Wall St")) |> 
  ggplot(aes(x = yearmoda, y = temp, color = name)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(se = FALSE, color = "white", alpha = 0.5) +
  theme(legend.position = "bottom") + 
  geom_errorbar(aes(ymin = min, ymax = max), alpha = 0.5)  
  
# despite being different boroughs, measured temperatures between stations are largely coincident - can get by with just one like Central Park
```

``` {r cursory graphs}
# Mosquito counts by year and borough - does mosquito season start earlier?

mosquitoes_2021_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

mosquitoes_2022_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |>   
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)


mosquitoes_2023_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

mosquitoes_2024_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

mosquitoes_2021_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

mosquitoes_2022_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

mosquitoes_2023_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

mosquitoes_2024_table |>
  group_by(borough, date) |> 
  summarize(
    count = n()
  ) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

wnv_mosquito_detection |> 
  mutate(count = 1) |> 
  group_by(date) |> 
  summarize(
    count = sum(count)
  ) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point()

# is heat vulnerability associated with WNV+ mosquitoes?

wnv_mosquito_detection |>
  mutate(
    month = month(date), 
    year = year(date)
  ) |> 
  group_by(zip_code, borough) |> 
  summarize(
    count = n()
  ) |> 
  left_join(hvi_zcta, by = join_by(zip_code)) |> 
  ggplot(aes(x = hvi, y = count, color = borough)) +
  geom_point()

# not really
```


```{r geocoding mosquito data by zcta, echo = FALSE}
# get geographic coordinates for use in ggplot later
# cannot use shapefiles for a singular year - may need to use 2010 MODZCTA shapefiles from DOHMH? https://github.com/nychealth/coronavirus-data/tree/master/Geography-resources
# or maybe this since this gives geoms alone? https://data.cityofnewyork.us/Health/Modified-Zip-Code-Tabulation-Areas-MODZCTA-/pri4-ifjk/about_data 

path <- "data/shapefiles/MODZCTA_2010.shp"

zip_shp <-
  path |>
  st_read() |> 
  janitor::clean_names() |>
  mutate(
    modzcta = as.double(modzcta),
    zip_code = as.double(label)
  ) |> 
  separate_longer_delim(label, delim = ", ")

# get MODZCTA for each ZIP code (approximating ZIP code as ZCTA)

mos_by_modzcta <- 
   left_join(wnv_mosquito_data, zip_shp, by = join_by("zip_code")) 
 
anti_join(wnv_mosquito_data, mos_by_modzcta) 

# still some ZCTAs without geographic areas - need to resolve later 

# NYC open data source
```

```{r map pos mosquito per modzcta}

mos_by_modzcta |> 
  filter(zip_code != modzcta) # no ZIP codes that were reallocated to a differently named MODZCTA, do not need to consolidate ZIP codes within the same MODZCTA


modzcta_2021 <-
  mos_by_modzcta |> 
  filter(year == 2021) |> 
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV+ mosquitoes",
    title = "2021"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25)) # highest count is 23 in 2024, 10314

modzcta_2022 <-
  mos_by_modzcta |>
  filter(year == 2022) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV+ mosquitoes",
    title = "2022"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2023 <-
  mos_by_modzcta |>
  filter(year == 2023) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV+ mosquitoes",
    title = "2023"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2024 <-
  mos_by_modzcta |>
  filter(year == 2024) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV+ mosquitoes",
    title = "2024"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2021 + modzcta_2022 + modzcta_2023 + modzcta_2024 + 
  plot_annotation(
    title = "WNV positive mosquitoes by MODZCTA",
    caption = "Data from NYC DOHMH, shapefile from NYC Open Data"
  ) +
  plot_layout(guides = "collect") 

```

```{r case data}

wnv_cases

weather_1999_2023 <-
  get_GSOD(
    years = c(1999:2023),
    station = c("725030-14732", "720553-99999", "744860-94789")
  ) |> 
  janitor::clean_names() |>
  select(name, latitude, longitude, yearmoda, temp, max, min, prcp, dewp) |>  # retain relevant variables - station name, latitude and longitude, date (yearmoda) mean temperature (temp), mean precipitation (prcp), mean dew point (dewp) to get an idea of water content in the air, max temperature, and min temperature
  mutate(
    temp = (temp * 9/5) + 32, # convert from Celsius to Fahrenheit
    max = (max * 9/5) + 32,
    min = (min * 9/5) + 32,
    prcp = (prcp * 0.0393701), # convert from mm to in
    year = year(yearmoda) # give stations more intuitive names
  ) |> 
  rename(date = yearmoda)
# 725030-14732 - LGA
# 725053-94728 - Central Park - only data from 2005-2024
# 744860-94789 - JFK 
# 720553-99999 - Port Authority Downtown Helipad - only data from 2016-2024


yearly_weather <-
  weather_1999_2023 |> 
  mutate(
    year = year(date)
  ) |> 
  group_by(year) |> 
  summarize(
    avg_temp = mean(temp),
    avg_min = mean(min),
    avg_max = mean(max), 
    avg_prcp = mean(prcp, na.rm = TRUE),
    avg_dewp = mean(dewp)
  )

wnv_cases <-
  wnv_cases |> 
  mutate(
    borough = case_match(
      borough, 
      "manhattan" ~ "Manhattan",
      "brooklyn" ~ "Brooklyn",
      "queens" ~ "Queens",
      "bronx" ~ "Bronx",
      "staten_island" ~ "Staten Island"
    )
  )

avg_hvi_borough <-
  left_join(hvi_zcta, zip_nbhd, by = join_by(zip_code)) |> 
    group_by(borough) |> 
    summarize(
      avg_hvi = mean(hvi)
    )

# is heat vulnerability associated with WNV+ human cases?

left_join(wnv_cases, yearly_weather, by = join_by(year)) |> 
  left_join(avg_hvi_borough, by = join_by(borough)) |> 
  ggplot(aes(x = avg_hvi, y = wnv_cases, fill = year, shape = borough)) +
  geom_point() + 
  stat_summary(fun.y = mean, color = "red")  # perhaps hvi is a parabolic distribution?



wnv_case_temp_hvi_df <- 
  wnv_mosquito_data |> 
  filter(!is.na(borough)) |>  # there are (likely nonresidential) ZIP codes with no boroughs and no detected WNV in mosquitoes and humans
  group_by(year, borough) |> 
  summarize(
    wnv_mosquitoes = sum(count) 
  ) |> 
  right_join(wnv_cases, by = join_by(year, borough)) |> 
  left_join(yearly_weather, by = join_by(year)) |> 
  left_join(avg_hvi_borough, by = join_by(borough)) |>  
  select(year, borough, starts_with("wnv_"), everything()) |> 
  arrange(year, borough)

```


```{r poisson assumptions}

# check assumption that mean and variance are approximately equal for each group of x (temperature)
# graphically 

left_join(wnv_cases, yearly_weather, by = join_by(year)) |> 
  left_join(avg_hvi_borough, by = join_by(borough)) |> 
  ggplot(aes(x = avg_temp, y = wnv_cases)) + 
  geom_point() +
  geom_smooth(se = FALSE)

# tabular check 
left_join(wnv_cases, yearly_weather, by = join_by(year)) |> 
  left_join(avg_hvi_borough, by = join_by(borough)) |> 
  group_by(avg_temp) |> 
  summarize(
    avg_count = mean(wnv_cases), 
    variance = var(wnv_cases)
  )

# are wnv+ mosquitoes detected associated with year and borough?

pos_mosquito_model <-
  wnv_case_temp_hvi_df |> 
  filter(year %in% 2021:2024) |> 
  glm(wnv_mosquitoes ~ year + borough,
      family = poisson,
      data = _)

pos_mosquito_model |> 
  broom::tidy()

pos_mosquito_model_saturated <-
wnv_case_temp_hvi_df |> 
  filter(year %in% 2021:2024) |> 
  glm(wnv_mosquitoes ~ year + borough + avg_temp + avg_hvi,
      family = poisson,
      data = _)

pos_mosquito_model_saturated |> 
  broom::tidy()

# this data aggregates ZIP code data together to borough level, may have greater power on ZIP code level 

pos_human_model <-
  wnv_case_temp_hvi_df |> 
  glm(wnv_cases ~ year + borough,
      family = poisson,
      data = _)

pos_human_model |> 
  broom::tidy() 

pos_human_model |> 
  broom::glance()
```

