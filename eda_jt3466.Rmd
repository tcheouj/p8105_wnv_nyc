---
title: "eda_jt3466"
author: "Johnstone Tcheou"
date: "2024-11-25"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(httr)
library(GSODR)
library(sf)
library(patchwork)
```


```{r wnv data import, echo = FALSE}
zip_nbhd <- read_html("https://p8105.com/data/zip_codes.html") |>
  html_table() |>
  first() |>
  janitor::clean_names() |>
  filter(!(county == "New York" & zip_code %in% c(10463, 11201))) |>#duplicated zip codes, both are *not* in New York County
  mutate(borough = str_replace_all(county, c(
    "Kings" = "Brooklyn",
    "New York" = "Manhattan",
    "Richmond" = "Staten Island"
  ))) |>
  select(zip_code, borough, neighborhood)


## 2021 - 2023 are simple HTML tables
mosquitoes_2024_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2024.page"
mosquitoes_2023_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2023.page"
mosquitoes_2022_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2022.page"
mosquitoes_2021_url <- "https://www.nyc.gov/site/doh/health/health-topics/west-nile-virus-activity-2021.page"

### 2024
mosquitoes_2024_table <- read_csv("data/mosquitoes_2024.csv") |>
  pivot_longer(cols = starts_with("date"), values_to = "date") |>
  select(-name, -detection_type) |> 
  mutate(
    date = case_match(
      date,
      "8/5/5024" ~ "8/5/2024",
      .default = date # one observation, 11426, with year miswritten as 5024-08-05 instead of 2024-08-05
    ),
    date = lubridate::mdy(date)
  ) |> 
  na.omit() 
   
### 2023
mosquitoes_2023_table <- mosquitoes_2023_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-neighborhood, -download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2023),
    date = lubridate::mdy(date)
  )

### 2022
mosquitoes_2022_table <- mosquitoes_2022_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2022),
    date = lubridate::mdy(date)
  )

### 2021
mosquitoes_2021_table <- mosquitoes_2021_url |>
  read_html() |> html_table() |> first() |>
  janitor::clean_names() |>
  separate_longer_delim(zip_code, delim = ", ") |>
  separate_longer_delim(zip_code, delim = ",\n") |>
  separate_longer_delim(zip_code, delim = ",") |> #this data is disgusting
  select(-download) |>
  mutate(
    zip_code = as.integer(zip_code),
    date = str_c(date, ", ", 2021),
    date = lubridate::mdy(date)
  ) |> 
  mutate(
    zip_code = case_when(
      zip_code == 1123 ~ 11236, # data entry error on the website, where 1123 is missing the last digit - per https://www.nyc.gov/assets/doh/downloads/pdf/wnv/2021/wnv-activity-bk-08192021.pdf it should be 11236
    .default = zip_code
    )
  )

wnv_mosquito_detection <- bind_rows(
  mosquitoes_2024_table,
  mosquitoes_2023_table,
  mosquitoes_2022_table,
  mosquitoes_2021_table,
) |> 
  left_join(y = zip_nbhd, by = join_by(zip_code)) |>
  select(zip_code, borough.x, date, neighborhood) |> 
  rename(borough = borough.x) |> # one ZIP code, 10000 has NA for borough as it is not in ZIP list - Central Park based on a Google search
  mutate(
    borough = case_when(
      zip_code == 10000 ~ "Manhattan",
      .default = borough
    ),
    neighborhood = case_when(
      zip_code == 10000 ~ "Central Park",
      .default = neighborhood
    )
  )

######### Heat Vulnerability by Neighborhood
heat_vuln <- read_csv("data/heat_vulnerability.csv") |>
  janitor::clean_names() #Already clean! Thank you NYC environment and health

######### West Nile Virus Cases by Year and Borough
wnv_cases <- read_csv("data/wnv_cases.csv") |>
  janitor::clean_names() |>
  pivot_longer(cols = c(
    bronx,
    brooklyn,
    manhattan,
    queens,
    staten_island
  ),
  names_to = "borough",
  values_to = "wnv_cases")

# May need to use ZCTA level HVI data instead of NTA level HVI 
# - ZCTA is designed to approximate ZIP codes, when our WNV counts are by ZIP code

hvi_zcta <- read_csv("https://data.cityofnewyork.us/resource/4mhf-duep.csv")  

hvi_wnv_zip <-
  inner_join(wnv_mosquito_detection, hvi_zcta, by = join_by(zip_code == zcta20))

hvi_wnv_zip |> 
  group_by(hvi) |> 
  summarize(
    count = n()
  )
```

```{r add no wnv zctas}
# get ZIP codes that did not have counts of WNV using anti_join with original ZIP code list (for generating proportions and to ensure ZIPs without cases can still be mapped later)

all_zctas <-
  zip_nbhd |> 
  pull(zip_code) |> 
  c(10000) 

wnv_pos_zctas <-
  wnv_mosquito_detection |> 
  pull(zip_code) |> 
  unique()

wnv_neg_zctas <-
  zip_nbhd |> 
  filter(!(zip_code %in% wnv_pos_zctas)) # summing negative and positive ZCTAs gets 131 instead of 130 from the ZIP list as 10000 not in the ZIP list

pos_cases_by_zcta <- 
  wnv_mosquito_detection |> 
  mutate(
    year = year(date)
  ) |> 
  group_by(zip_code, year) |> 
  summarize(
    count = n()
  ) |> 
  arrange(zip_code, year) 

neg_cases_by_zcta <-
  wnv_neg_zctas |> 
  pull(zip_code) |> 
  expand_grid(
    zip_code = _,
    year = c(2021, 2022, 2023, 2024)
  ) |> 
  mutate(
    count = 0
  )

cases_by_zcta <- 
  rbind(neg_cases_by_zcta, pos_cases_by_zcta) |> 
  arrange(zip_code, year) |> 
  left_join(zip_nbhd, by = join_by(zip_code)) |>  # bring borough back in after getting counts grouped by zip
  mutate( # catch the 10000 ZIP code
    borough = case_when(
      zip_code == 10000 ~ "Manhattan",
      .default = borough
    ),
    neighborhood = case_when(
      zip_code == 10000 ~ "Central Park",
      .default = neighborhood
    )
  )


### check this - if i can get zctas without cases for each year to appear then i can calculate correct proportions and fix the maps
prptn_wnv_borough <- # calculate each borough's proportion of positive ZIPs out of total ZIPs in that borough
  cases_by_zcta |> 
  mutate(
    detected = case_when(
      count > 0 ~ 1,
      count == 0 ~ 0, 
      .default = NA
    )
  ) |> 
  group_by(borough, year) |> 
  summarize(
    total = n(),
    positive = sum(detected)
  ) |> 
  mutate(prtpn_pos = positive/total)
```


```{r gsodr data import, echo = FALSE}

# Bushwick is the geographical center of NYC, providing the following latitude and longitude coordinates 
# Wakefield at the top of the Bronx is around 33 km/20.5 mi away from Bushwick, creating the radius of stations to search for
# Filter for non NYC stations, by filtering out NJ and filtering out Kings Point and Sandy Hook and other Long Island locations

stations <-
  nearest_stations(
    LAT = 40.6958, 
    LON = -73.9171,
    distance = 33
  ) |> 
  filter(STATE != "NJ" & !(NAME %in% c("KINGS POINT", 
                                       "SANDY HOOK", 
                                       "BERGEN POINT", 
                                       "MITCHEL FIELD", 
                                       "HEMPSTEAD MITCHELL FLD AFB", 
                                       "AMBROSE LIGHT  NY", 
                                       "AMBROSE / FT. TILDEN", 
                                       "FREEPORT")))


# Some stations only have historical data preceding our years of interest of 2021-2024, these have been filtered out

stations <- 
  stations |> 
  filter(!(STNID %in% c("999999-14732",
                        "725033-94728",
                        "725060-94728",
                        "999999-94728",
                        "744976-99999",
                        "999999-14786",
                        "999999-94789",
                        "725026-99999",
                        "997439-99999")))
weather_df <-
  get_GSOD(
    years = c(2021:2024),
    station = stations$STNID
  ) |> 
  janitor::clean_names() |>
  select(name, latitude, longitude, yearmoda, temp, max, min, prcp, dewp) |>  # retain relevant variables - station name, latitude and longitude, date (yearmoda) mean temperature (temp), mean precipitation (prcp), mean dew point (dewp) to get an idea of water content in the air, max temperature, and min temperature
  mutate(
    temp = (temp * 9/5) + 32, # convert from Celsius to Fahrenheit
    max = (max * 9/5) + 32,
    min = (min * 9/5) + 32,
    prcp = (prcp * 0.0393701), # convert from mm to in
    year = year(yearmoda), # give stations more intuitive names
    name = case_match(
      name, 
      "PORT AUTH DOWNTN MANHATTAN WALL ST HEL" ~ "Wall St",
      "LA GUARDIA AIRPORT" ~ "LGA",
      "CENTRAL PARK" ~ "Central Park",
      "JOHN F KENNEDY INTERNATIONAL AIRPORT" ~ "JFK",
      "THE BATTERY" ~ "The Battery"
    )
  )
```

``` {r cursory graphs}
# Mosquito counts by year and borough - does mosquito season start earlier?
grouping_counts <- function(x) {
  df <-
    x |> 
    group_by(borough, date) |> 
    summarize(
      count = n()
    )
  
  df
}

borough_counts <-
  tibble(
    counts = list(mosquitoes_2021_table, mosquitoes_2022_table, mosquitoes_2023_table)
  ) |> 
  mutate(
    borough_counts = map(counts, grouping_counts)
  ) |>
  select(borough_counts) |> 
  unnest(cols = c(borough_counts)) |> 
  mutate(
    month = month(date),
    year = year(date)
  ) |> 
  select(borough, month, year, date, count)

borough_counts |>
  filter(year == 2021) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

borough_counts |>
  filter(year == 2022) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

borough_counts |>
  filter(year == 2023) |> 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2021) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2022) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_bar(stat = "identity") +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2023) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_bar(stat = "identity") +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2021) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(stat = "identity") +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2022) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_bar(stat = "identity") +
  facet_grid(~borough)

borough_counts |> 
  filter(year == 2023) |> 
  ggplot(aes(x = date, y = count, fill = borough)) +
  geom_col(width = 2.0) +
  facet_grid(~borough)


# is there much variation between the different weather stations?

weather_df |>
#  filter(name %in% c("Central Park", "Wall St")) |> 
  ggplot(aes(x = yearmoda, y = temp, color = name)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(se = FALSE, color = "white", alpha = 0.5) +
  theme(legend.position = "bottom") + 
  geom_errorbar(aes(ymin = min, ymax = max), alpha = 0.5)  
  
# despite being different boroughs, measured temperatures between stations are largely coincident - can get by with just one like Central Park
```


```{r geocoding count data by zcta, echo = FALSE}
# get geographic coordinates for use in ggplot later
# cannot use shapefiles for a singular year - may need to use 2010 MODZCTA shapefiles from DOHMH? https://github.com/nychealth/coronavirus-data/tree/master/Geography-resources
# or maybe this since this gives geoms alone? https://data.cityofnewyork.us/Health/Modified-Zip-Code-Tabulation-Areas-MODZCTA-/pri4-ifjk/about_data 

path <- "data/shapefiles/MODZCTA_2010.shp"

zip_shp <-
  path |>
  st_read() |> 
  janitor::clean_names() |>
  mutate(
    modzcta = as.double(modzcta),
    zip_code = as.double(label)
  ) |> 
  separate_longer_delim(label, delim = ", ")

# get MODZCTA for each ZIP code (approximating ZIP code as ZCTA)

cases_by_modzcta <- 
   left_join(cases_by_zcta, zip_shp, by = join_by("zip_code")) 
 
anti_join(cases_by_zcta, cases_by_modzcta) 

# still some ZCTAs without geographic areas - need to resolve later 

# NYC open data source
```

```{r map counts per modzcta}

cases_by_modzcta |> 
  filter(zip_code != modzcta) # no ZIP codes that were reallocated to a differently named MODZCTA, do not need to group by and sum as below 

# cases_by_modzcta |> 
#   group_by(modzcta, year, geometry) |> 
#   summarize(
#     count = sum(count)
#   ) |> 
#   filter(year == 2021) |> 
#   ggplot(aes(fill = count, geometry = geometry)) +
#   geom_sf()

modzcta_2021 <-
  cases_by_modzcta |> 
  filter(year == 2021) |> 
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV cases",
    title = "2021"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25)) # highest count is 23 in 2024, 10314

modzcta_2022 <-
  cases_by_modzcta |>
  filter(year == 2022) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV cases",
    title = "2022"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2023 <-
  cases_by_modzcta |>
  filter(year == 2023) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV cases",
    title = "2023"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2024 <-
  cases_by_modzcta |>
  filter(year == 2024) |>
  ggplot(aes(fill = count, geometry = geometry)) +
  geom_sf() +
  labs(
    fill = "WNV cases",
    title = "2024"
  ) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  viridis::scale_fill_viridis(limits = c(0, 25))

modzcta_2021 + modzcta_2022 + modzcta_2023 + modzcta_2024 + 
  plot_annotation(
    title = "NYC WNV cases by MODZCTA",
    caption = "Data from NYC DOHMH, shapefile from NYC Open Data"
  ) +
  plot_layout(guides = "collect") 

# cases_by_modzcta |> 
#    filter(year == 2024) |> 
#    arrange(desc(count))
```

