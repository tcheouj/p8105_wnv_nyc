---
title: "Regression Models"
output: 
  html_document:
    code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = NA
)
library(tidyverse)
library(modelr)
library(broom)
library(rvest)
library(httr)
library(GSODR)
library(sf)
library(patchwork)
library(car)
library(GGally)
library(broom.helpers)
```

In this section, we show our model building process. We start with an uninformative month-based model and move to a more granular autoregressive model with temperature effects.

# Data import

First, we need to import our WNV data and predictor data. Ultimately, we are only modeling WNV+ mosquitoes, so we are actually just using the mosquito data and the weather data to predict WNV+ mosquito counts. Since Heat Vulnerability Index (HVI) is a quantitative proxy for human vulnerability to extreme heat and heatstroke, we do not hypothesize it to be causally relevant. This is supported by the lack of association between HVI and WNV+ mosquito count. 

```{r data import, message=FALSE}
wnv_cases <- read_csv("cleaned_data/wnv_cases.csv")
wnv_mosquitoes <- read_csv("cleaned_data/wnv_mosquitoes.csv") 
heat_vuln <- read_csv("cleaned_data/heat_vuln.csv")
day_weather <- read_csv("cleaned_data/day_weather.csv")
```

# Model with year 

This is the simplest model, predicting counts of WNV+ mosquitoes using year. Using our mosquito count data, we want to get counts per year to model from. As such, we `mutate` to create a year variable based on the date variable, `group_by` year, and calculate the count for each year.

```{r year data}
mosq_count_by_year <- 
  wnv_mosquitoes |>
  mutate(year = lubridate::year(date)) |>
  group_by(year) |>
  summarise(count = n()) 

mosq_count_by_year |> 
  knitr::kable(col.names = c("Year", "Count of WNV+ mosquitoes")) 
```

```{r year model}
fit1 <- glm(count ~ year, mosq_count_by_year, family = "poisson")

fit1 |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Tes statistic", "p value")
  )

fit1 |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )
```

Since we are modeling counts of WNV+ mosquitoes, viable models for count data would be a Poisson regression or negative binomial regression. Our first initial model is a Poisson regression predicting counts of mosquitoes using year alone. 

As expected, year does not really predict count much, with an estimated `r fit1 |> broom::tidy() |> filter(term == "year") |> pull(estimate) |> round(4)` count of mosquitoes for each additional year. The parameter is also not significant at the 0.05 level, with a p value of `r fit1 |> broom::tidy() |> filter(term == "year") |> pull(p.value) |> round(4)`.

# Model with month 

As for the simple model using year, we want to get counts of mosquitoes but per month this time instead of year. We create a month variable using `mutate`, and `group_by` is used again to calculate counts of mosquitoes per month.

```{r month data}

mosq_count_by_month <- 
  wnv_mosquitoes |>
  mutate(month = lubridate::month(date)) |>
  group_by(month) |>
  summarise(count = n())

mosq_count_by_month |> 
  knitr::kable(col.names = c("Month", "Count of WNV+ mosquitoes"))

mosq_count_by_month |> 
  ggplot(aes(x = month, y = count)) +
  geom_bar(stat = "identity", fill = "#440154FF") +
  guides(
    fill = "none"
  )

```

As shown on the table, the bulk of the counts are in the middle of summer in August, with `r mosq_count_by_month |> pull(count) |> max()` mosquitoes, tapering off towards the beginning and end in June and October. The start of data collection in June has the least number of WNV+ mosquitoes with `r mosq_count_by_month |> pull(count) |> min()`. When plotted, the distribution is also approximately normal.

```{r month model}
fit2 <- glm(count ~ month, mosq_count_by_month, family = "poisson") 

fit2 |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

fit2 |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

```

Our second model modeling mosquito count predicted by month only has a significant regression parameter of `r fit2 |> tidy() |>  filter(term == "month") |> pull(estimate) |> round(4)` mosquitoes for every increase by 1 month, with a p value of `r fit2 |> tidy() |>  filter(term == "month") |> pull(p.value) |> round(4)`.

```{r month model fit}
mosq_count_by_month |> 
  cbind(pred = predict(fit2, type = "response")) |> 
  ggplot(aes(x = month, y = count)) +
  geom_point(color = "#404688FF", alpha = 0.5) + 
  geom_line(aes(y = pred), size = 0.6)
```

However, despite a significant model, the model does not fit our dataset well, so it is not useful in predicting counts. When plotting the predicted values against the observed values, the predicted values are linear since model is represented as a linear term, while our observed counts are parabolic.

```{r linear and quadratic month model}
fit3 <- glm(count ~ month + I(month^2), mosq_count_by_month, family = "poisson")

fit3 |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

fit3 |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )
```

With this model, both linear and second order terms are significant predictors of mosquito counts, with p values of 
`r fit3 |> tidy() |>  filter(term == "month") |> pull(p.value) |> round(6)` and `r fit3 |> tidy() |>  filter(term == "I(month^2)") |> pull(p.value) |> round(6)`, respectively.

```{r linear and quadratic month fit}
mosq_count_by_month |> 
  cbind(pred = predict(fit3, type = "response")) |> 
  ggplot(aes(x = month, y = count)) +
  geom_point(alpha = 0.5, size = 2) + 
  geom_line(aes(y = pred), color = "#3B528BFF", size = 0.6)

```

With an included second order term for month, our predicted values better fit the observed values, depicting the parabolic shape of the data. 

# Model with month and year

Now that we are predicting both month and year, we want to get counts per each combination of month and year. We `mutate` to create month and year variables again, `group_by` month and year both this time, and get the mosquito counts per each combination as follows. 

```{r month year data, message=FALSE}
mosq_month_year <- 
  wnv_mosquitoes |>
  mutate(month = lubridate::month(date),
         year = lubridate::year(date)) |>
  group_by(year, month) |>
  summarise(count = n()) 

mosq_month_year |> 
  knitr::kable(col.names = c("Year", "Month", "Count of WNV+ mosquitoes"))
```

To determine whether year is a significant additional predictor to a model that already has linear and second order terms for month, we created a Poisson model with just the two month terms and one with both month terms and year as a predictor.

```{r month year model}
fit3.5 <- glm(count ~ month + I(month^2), mosq_month_year, family = "poisson")
fit4 <- glm(count ~ month + I(month^2) + year, mosq_month_year, family = "poisson")

fit3.5 |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

fit3.5 |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

fit4 |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

fit4 |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

anova(fit3.5, fit4) |> 
  tidy()

```

In the model with year as a predictor, year is not significantly predicting mosquito counts, with a p value of `r fit4 |> tidy() |> filter(term == "year") |> pull(p.value) |> round(4)`. When conducting a chi-squared test to determine whether the addition of year is significant, the associated p value is `r anova(fit3.5, fit4) |> tidy() |> filter(term == "count ~ month + I(month^2) + year") |> pull(p.value) |> round(4)`. Adding year to a model that already has month as linear and second order terms does not significantly improve model prediction. 

```{r poisson overdispersion}
mosq_month_year |> 
  cbind(pred = predict(fit4, type = "response")) |> 
  mutate(monthyear = (year - 2021)*12 + month) |> 
  ggplot(aes(x = monthyear, y = count)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = pred, group = year), color = "#365D8DFF", size = 0.6)

mosq_month_year |> 
  cbind(
    pred = predict(fit4, type = "response"),
    resid = resid(fit4)
  ) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(color = "#31688EFF",, size = 3) + 
  geom_hline(yintercept = 0)

performance::check_overdispersion(fit4) 


```

However, before proceeding with the next model, we wanted to check model fit and see if the assumptions of the Poisson distribution still hold. When graphing the predicted values for the model with month and year, it is able to capture the peaks and declines in counts better than the simple linear model, but isn't quite the best fit. 

One of the Poisson model assumptions is that variance is approximately equal to the mean, so as the mean increases, the variance does as well. However, when the observed variance is much higher than the mean, and therefore higher than the expected variance, the data is overdispersed and a Poisson model may not be the best choice for the data. 

When plotting the residuals vs fitted values, we would expect a fanning pattern as we would see the variance increase as the mean predicted values increase. However, at higher predicted values, the variance starts to decrease, indicating overdispersion. 

This is confirmed using the `check_overdispersion` test from the `performance` package, which tests the dispersion ratio of observed variance to the expected variance. The null hypothesis of this test is that the dispersion ratio is 1, so the observed and expected variances are equal. However, our test result is significant, rejecting the null hypothesis and indicating our model is overdispersed for our data. This suggests we may need to use a different model that accounts for dispersion, like a negative binomial model. 



# Model with week and year

To create a model that includes week as a parameter, we need aggregated mosquito counts by year and week. This is done again by `mutate` to make year and week variables, creating a variable `weekyear` that calculates the number of weeks from 2021 (the first year of available mosquito data), and grouping counts by combinations of year and week. This `weekyear` variable is used to merge with weather data from GSOD. 

Daily weather readings from GSOD are aggregated to be by week, calculating the average temperature, precipitation, dewpoint, maximum temperature, and minimum temperature across several stations in NYC, by combinations of year and week. Additionally, since week-to-week weather is likely not independent as the weather conditions of the prior week probably influences the following week, lagging temperature variables are also created for the above weather variables. `weekyear` was also created. 

The mosquito counts and weather data are merged by `weekyear`, with duplicate columns from the weather data dropped. As with the weather, circulating WNV+ mosquitoes from week to week are also hypothesized to not be independent, since the presence of WNV+ circulating the week prior will persist and infect other mosquitoes in the following week. Therefore, lagging mosquito counts are also created.

```{r week and temp data}

# mosq_cases |> 
#   ggplot(aes(x = weekyear, y = count)) +
#   geom_point()
mosq_cases <-
  wnv_mosquitoes |>
  mutate(
    year = lubridate::year(date),
    week = lubridate::week(date)) |>
  group_by(year, week) |>
  summarise(count = n()) |>
  mutate(weekyear = (year - 2021)*52 + week) 
  
weekly_weather <- 
  day_weather |>
  mutate(
    year = lubridate::year(date),
    week = lubridate::week(date)) |>
  group_by(year, week) |>
  summarise(avg_temp = mean(avg_temp),
            avg_prcp = mean(avg_prcp),
            avg_dewp = mean(avg_dewp),
            avg_max = mean(avg_max),
            avg_min = mean(avg_min)) |>
  arrange(year, week) |>
  mutate(lag_temp = lag(avg_temp),
         lag_prcp = lag(avg_prcp),
         lag_dewp = lag(avg_dewp),
         lag_max =  lag(avg_max),
         lag_min =  lag(avg_min)) |>
  mutate(weekyear = (year - 2021)*52 + week) #week since start of 2021

mosq_cases_temp <- 
  mosq_cases |>
  left_join(y = weekly_weather, by = join_by(weekyear)) |>
  select(-ends_with(".y")) |>
  rename(year = year.x, week = week.x) |>
  mutate(
    id = row_number(),
    lag_count = lag(count),
    lag_count = case_when(
      is.na(lag_count) ~ 0,
      .default = lag_count
    )
  ) |>
  na.omit()

mosq_cases_temp |> 
  head() |>
  knitr::kable()
```

The first model is just the week as a linear and a second order term as well as year to predict mosquito counts, using a negative binomial model this time.

```{r week year model}
null_fit <- MASS::glm.nb(count ~ week + I(week^2) + year, mosq_cases_temp)

null_fit |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

null_fit |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

mosq_cases_temp |> 
  cbind(pred = predict(null_fit, type = "response")) |> 
  ggplot(aes(x = weekyear, y = count)) +
  geom_point(alpha = 0.5, size = 2) + 
  geom_line(aes(y = pred, group = year), color = "#472D7BFF", size = 0.6)

mosq_cases_temp |> 
  cbind(resid = resid(null_fit)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#472D7BFF") # null model works well
```

All predictors in the model are significant, with p values for first order week and second order week of `r null_fit |> tidy() |> filter(term == "week") |>  pull(p.value) |> round(6)` and `r null_fit |> tidy() |> filter(term == "I(week^2)") |>  pull(p.value) |> round(6)`, respectively. Year has a p value of `r null_fit |> tidy() |> filter(term == "year") |>  pull(p.value) |> round(6)`. 

When fitting the model to the data, we see that it also fits well.

# Fitting temperature

Before we continue, we note another regression assumption may be violated. A standard generalized linear model assumes that the samples are independent. In most situations this assumption is trivial, but in our case it becomes an issue. Since mosquitoes reproduce, mosquito incidence in a sufficiently short time period is highly dependent on the incidence in a previous time period. The null model is essentially guessing this effect based on the average in the other years. This leads to an inappropriate fit for the data in 2021. To address this problem, we fit an autoregressive model based on the previous week. For the first week of each year, we assume the count of WNV+ mosquitoes is 0.

```{r lag count model}
ar_fit <- MASS::glm.nb(count ~ lag_count, mosq_cases_temp)

ar_fit |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

ar_fit |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

mosq_cases_temp |> 
  cbind(pred = predict(ar_fit, type = "response")) |> 
  ggplot(aes(x = weekyear, y = count)) +
  geom_point(alpha = 0.5, size = 2) + 
  geom_line(aes(y = pred, group = year), color = "#31688EFF", size = 0.6)

mosq_cases_temp |> 
  cbind(resid = resid(ar_fit)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#31688EFF") 
```

Now, we have a model with just the lagging count of mosquitoes. The estimated increase in counts based on the prior count of mosquitoes is `r ar_fit |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)` with a p value of `r ar_fit |> tidy() |> filter(term == "lag_count") |> pull(p.value) |> round(6)`. The lagging mosquito count is then a significant predictor of estimated mosquito counts, and the graph illustrates the model fits the observed points well, except for the peaks in the 2021 data. Further, there appears to be a positive bias in the model when the count is close to zero. 

```{r lag count temp model}
ar_temp_fit <- MASS::glm.nb(count ~ lag_count + lag_temp, mosq_cases_temp)

ar_temp_fit |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

ar_temp_fit |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

mosq_cases_temp |> 
  cbind(
    pred_ar = predict(ar_fit, type = "response"),
    pred_ar_temp = predict(ar_temp_fit, type = "response")
  ) |> 
  ggplot(aes(x = weekyear, y = count)) +
  geom_point(alpha = 0.5, size = 2) + 
  geom_line(aes(y = pred_ar, color = "AR", group = year), linetype = "dashed", size = 0.6) +
  geom_line(aes(y = pred_ar_temp, color = "AR+temp", group = year), linetype = "solid", size = 0.6) +
  scale_color_manual(name = "models", values = c("AR" = "#31688EFF", "AR+temp" = "#1F9A8AFF"))

mosq_cases_temp |> 
  cbind(resid = resid(ar_temp_fit)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#1F9A8AFF") 

```

Afterwards, a model that also has lagging average temperature has significant terms for both lagging temperature and lagging mosquito counts. The associated estimate for lagging count is now `r ar_temp_fit |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)`, with a p value of `r ar_temp_fit |> tidy() |> filter(term == "lag_count") |> pull(p.value) |> round(6)`. For lagging temperature, the estimate is `r ar_temp_fit |> tidy() |> filter(term == "lag_temp") |> pull(estimate) |> round(4)` , with a  p value of `r ar_temp_fit |> tidy() |> filter(term == "lag_temp") |> pull(p.value) |> round(6)`. This model indicates lagging temperature has a larger effect on estimating mosquito counts than lagging mosquito counts. Compared to the model with just lagging mosquito counts, lagging mosquito counts has a slightly smaller effect on predicting counts in this model. Note the addition of the temperature variable improves the prediction notably for 2021 and for low count data points.

Lastly, when we explored Poisson models, we had a saturated model that included precipitation as a predictor and found it was a considerably significant predictor with a larger effect size than the other predictors. However, since a Poisson regression is overdispersed for our data, we wanted to see if precipitation also has a considerable impact on predicting mosquito counts in a negative binomial regression model. 

```{r lag count temp rain}
ar_temp_rain_fit <- MASS::glm.nb(count ~ lag_count + lag_temp + lag_prcp, mosq_cases_temp)

ar_temp_rain_fit |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

ar_temp_rain_fit |> 
  glance() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Null deviance", "Null df", "Log likelihood", "AIC", "BIC", "Deviance", "Residual df", "Number of observations")
  )

mosq_cases_temp |> 
  cbind(
    pred_null = predict(null_fit, type = "response"),
    pred_ar_temp = predict(ar_temp_fit, type = "response"),
    pred_ar_temp_rain = predict(ar_temp_rain_fit, type = "response")
  ) |> 
  ggplot(aes(x = weekyear, y = count)) +
  geom_point(alpha = 0.5, size = 3) + 
  geom_line(aes(y = pred_null, color = "null", group = year), linetype = "dotted", size = 1.9) +
  geom_line(aes(y = pred_ar_temp, color = "AR+temp", group = year), linetype = "solid", size = 0.6) +
  geom_line(aes(y = pred_ar_temp_rain, color = "AR+temp+rain", group = year), linetype = "dashed", size = 0.6) +
  scale_color_manual(name = "models", values = c("null" = "#472D7BFF", "AR+temp" = "#1F9A8AFF", "AR+temp+rain" = "#5DC863FF"))

mosq_cases_temp |> 
  cbind(resid = resid(ar_temp_rain_fit)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#5DC863FF") 
```

For this model, the estimated coefficient for lagging mosquito counts is `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)`, compared to its coefficient in the model without rain with `r ar_temp_fit |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)`. The p value for this estimate is `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_count") |> pull(p.value) |> round(4)`, while it has a p value in the prior model of `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_count") |> pull(p.value) |> round(4)`. With lagging average temperature, the estimate is now `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_temp") |> pull(estimate) |> round(4)` (p = `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_temp") |> pull(p.value) |> round(6)` compared to `r ar_temp_fit |> tidy() |> filter(term == "lag_temp") |> pull(estimate) |> round(4)` (p = `r ar_temp_fit |> tidy() |> filter(term == "lag_count") |> pull(p.value) |> round(6)`)). 

The new term of lagging precipitation has an estimate of `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_prcp") |> pull(estimate) |> round(4)` with a p value of `r ar_temp_rain_fit |> tidy() |> filter(term == "lag_prcp") |> pull(p.value) |> round(6)`. Despite having a large effect size compared to the other predictors, it is now no longer a significant estimate in a negative binomial model. This is likely from adjusting for the overdispersion, which would have biased the standard error of the lagging precipitation estimate towards zero and artificially inflated the significance. In terms of model fit, including the lagging precipitation term only slightly improved model fit for 2023. As such, for maintaining parsimony, our final model only includes lagging average temperature and lagging mosquito counts, not lagging rain.


```{r final model}
# rain doesnt significantly contribute, but makes fit visually better
# especially for 2023

final_fit <- ar_temp_fit

final_fit |> 
  ggcoef_model(
    variable_labels = c(
      lag_count = "Lagging \nmosquito count",
      lag_temp = "Lagging \naverage temperature"
    ),
    signif_stars = FALSE
    ) +
    labs(
      title = "Predicted WNV+ mosquito counts in NYC",
      x = "Negative binomial regression estimated coefficients"
    )

```

## Outlier Analysis
```{r influence analysis}
augment_df <- 
  augment(final_fit) |>
  mutate(
    id = row_number(),
    avg_hat_2 = 2*mean(.hat),
    avg_hat_3 = 3*mean(.hat),
    influential = case_when(
      .cooksd > avg_hat_2 ~ 1,
      .cooksd > avg_hat_3 ~ 1,
      .std.resid > 2 ~ 1, 
      .default = 0
    )
  ) |> 
  select(id, everything())

avg_hat_2 <- 
  augment_df |> 
  pull(avg_hat_2) |> 
  nth(1)
  
avg_hat_3 <-
  augment_df |> 
  pull(avg_hat_3) |> 
  nth(1)
  
augment_df |> 
  ggplot(aes(x = .hat, y = .std.resid)) + 
  geom_point(aes(size = .cooksd, color = .cooksd)) +
  geom_hline(
    yintercept = c(-2, 0, 2)
  ) +
  geom_vline(
    xintercept = c(avg_hat_2, avg_hat_3)
  ) +
  guides(
    color = "none",
    size = "none"
  )

augment_df |> 
  filter(influential == 1) |> 
  select(-c(id, starts_with("avg_hat"), influential)) |> 
  knitr::kable(
    digits = 4,
    col.names = c("Count", "Lagging count", "Lagging temperature", "Fitted", "Residual", "Hat", "Sigma", "Cook's distance", "Studentized residuals")
  )

# car::influencePlot(final_fit) |> 
#  knitr::kable(col.names = c("Studentized residuals", "Hat values (influence)", "Cook's distance"))
```

When looking at influential points in our dataset, there are 3 different influential points that may warrant further analysis to see if omitting them alter the model parameter estimates.

```{r omit influential points}

influential_ids <- 
  augment_df |> 
  filter(influential == 1) |> 
  pull(id)

final_fit_omitted <-
  mosq_cases_temp |> 
  select(id, count, lag_count, everything()) |> 
  filter(!(id %in% influential_ids)) |> 
  MASS::glm.nb(count ~ lag_count + lag_temp, data = _)
  
final_fit |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  )

final_fit |> 
  ggcoef_model(
    variable_labels = c(
      lag_count = "Lagging \nmosquito count",
      lag_temp = "Lagging \naverage temperature"
    ),
    signif_stars = FALSE
    ) +
    labs(
      title = "Predicted WNV+ mosquito counts in NYC",
      x = "Negative binomial regression estimated coefficients"
    )

final_fit_omitted |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  ) 

final_fit_omitted |> 
  ggcoef_model(
    variable_labels = c(
      lag_count = "Lagging \nmosquito count",
      lag_temp = "Lagging \naverage temperature"
    ),
    signif_stars = FALSE
    ) +
    labs(
      title = "Predicted WNV+ mosquito counts in NYC",
      x = "Negative binomial regression estimated coefficients"
    )


```

When omitting the influential points, the lagging count estimate does not change much, going from `r final_fit |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)` to `r final_fit_omitted |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)`. The lagging temperature estimate does change a bit, changing from `r final_fit |> tidy() |> filter(term == "lag_temp") |> pull(estimate) |> round(4)` to `r final_fit_omitted |> tidy() |> filter(term == "lag_count") |> pull(estimate) |> round(4)`.

```{r predicted vals}
pred_vals_omit <-
  mosq_cases_temp |> 
  filter(!(id %in% influential_ids)) |>  
  cbind( 
    pred_fin_omit = predict(final_fit_omitted, type = "response")
  ) |> 
  select(id, count, pred_fin_omit)

pred_vals <-
  mosq_cases_temp |> 
  cbind(
    pred_fin = predict(final_fit, type = "response")
  ) |> 
  select(id, count, pred_fin)

inner_join(pred_vals, pred_vals_omit, by = join_by(id)) |> 
  select(-ends_with(".y")) |>
  rename(count = count.x) |> 
  pivot_longer(
    cols = starts_with("pred_fin"),
    values_to = "prediction",
    names_to = "model",
    names_prefix = "pred_") |>
  mutate(
    model = case_when(
      model == "fin" ~ "original",
      .default = "outliers omitted"
    )
  ) |>
  ggplot(aes(x = count, y = prediction, color = model)) +
  geom_point() +
  labs(
    y = "Predicted values",
    x = "Observed values"
  )

mosq_cases_temp |> 
  select(id, count, lag_count, everything()) |> 
  filter(!(id %in% influential_ids)) |>
  cbind(resid = resid(final_fit_omitted)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#5DC863FF") 
```

Plotting predicted values from both models shows a reduction in the positive bias from the full model. This is a slight improvement, but the residuals vs predicted values plot shows this model does not completely characterize the response data. There remains a quadratic trend not accounted for by our model.

## Adding Quadratic Lag Terms
```{r}
final_fit_quadratic_counts <-
  mosq_cases_temp |> 
  MASS::glm.nb(count ~ lag_count + I(lag_count^2) + lag_temp, data = _)

final_fit_quadratic_counts |> 
  tidy() |> 
  knitr::kable(
    digits = 4,
    col.names = c("Term", "Estimate", "Standard error", "Test statistic", "p value")
  ) 

mosq_cases_temp |> 
  cbind(resid = resid(final_fit_quadratic_counts)) |> 
  ggplot(aes(x = count, y = resid)) +
  geom_point(color = "#5DC863FF") + 
  geom_hline(yintercept = 0) +
  labs(title = "Partial Residuals for Quadratic Count Model (Counts)")

mosq_cases_temp |> 
  cbind(resid = resid(final_fit_quadratic_counts)) |> 
  ggplot(aes(x = lag_temp, y = resid)) +
  geom_point(color = "#5DC863FF") + 
  geom_hline(yintercept = 0) +
  labs(title = "Residuals for Quadratic Count Model (Temps)")

mosq_cases_temp |>
  cbind(prediction = predict(final_fit_quadratic_counts, type = "response")) |> 
  ggplot(aes(x = weekyear, y = count, group = year)) +
  geom_point() + 
  geom_line(aes(x = weekyear, y = prediction), color = "#5DC863FF") +
  labs(title = "Predictions for Quadratic Count Model")
```

Adding a quadratic term for the previous week's count of mosquitoes improved the residual behavior, but caused unusual behavior in the predictions. The does not appear to be a non-linear trend for the partial residuals of the lagged temperature variable.

```{r}
augment_df <- 
  augment(final_fit_quadratic_counts) |>
  mutate(
    id = row_number(),
    avg_hat_2 = 2*mean(.hat),
    avg_hat_3 = 3*mean(.hat),
    influential = case_when(
      .cooksd > avg_hat_2 ~ 1,
      .cooksd > avg_hat_3 ~ 1,
      .std.resid > 2 ~ 1, 
      .default = 0
    )
  ) |> 
  select(id, everything())

avg_hat_2 <- 
  augment_df |> 
  pull(avg_hat_2) |> 
  nth(1)
  
avg_hat_3 <-
  augment_df |> 
  pull(avg_hat_3) |> 
  nth(1)
  
augment_df |> 
  ggplot(aes(x = .hat, y = .std.resid)) + 
  geom_point(aes(size = .cooksd, color = .cooksd)) +
  geom_hline(
    yintercept = c(-2, 0, 2)
  ) +
  geom_vline(
    xintercept = c(avg_hat_2, avg_hat_3)
  ) +
  guides(
    color = "none",
    size = "none"
  ) +
  labs(title = "Influence Plot for Quadratic Count Model",
       y = "Standardized Residuals",
       x = "Hat Value")

```

Again, we look for influential outliers and see whether they made a difference in the analysis. Comparing influence versus standardized residual shows better performance than the linear count model.